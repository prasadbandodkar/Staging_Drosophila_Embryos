{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KV3EBHUvXFS"
      },
      "source": [
        "# Staging Drosophila Embryos\n",
        "The objective of the project is to develop a model that would predict the stage of the development of a Drosophila embryo based on the image of the embryo. The final model would take as input an image of the the embryos stained for DAPI and output the development time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTOF-Kn2vXFX"
      },
      "source": [
        "## Colab-related imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "TIpS6_RFvXFY",
        "outputId": "41c21a85-613f-47c3-e99a-ca2f34729e5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95fd4d10-8f76-43a2-aa90-0776144fa6cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95fd4d10-8f76-43a2-aa90-0776144fa6cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving CrossSections.zip to CrossSections.zip\n"
          ]
        }
      ],
      "source": [
        "# import data into google colab\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcZSR6gwvjw5",
        "outputId": "4ac9a65e-4474-40cf-ca3f-da7aa02ba843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI3uNw3VvXFa"
      },
      "outputs": [],
      "source": [
        "# unzip data\n",
        "import zipfile\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['CrossSections.zip']), \"r\")\n",
        "zf.extractall('CrossSections')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfCeln_CvXFb"
      },
      "source": [
        "## Specifications\n",
        "This section specifies libraries to import, folder locations and filenames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Specify libraries to import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l5aobut8vXFb"
      },
      "outputs": [],
      "source": [
        "# Standard import statements\n",
        "#\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import local modules\n",
        "#\n",
        "from data import Data\n",
        "from tfimage import TFImage\n",
        "from cvimage import CVImage, NuclearLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Specify paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "# Folder specifications\n",
        "#\n",
        "sys_folder  = '/Volumes/X2/Projects/staging/Data/'\n",
        "data_folder = sys_folder + 'data/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXgdJpchvXFe"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        " This section is for data preparation. It reads the csv files and creates a dataset each for training and validation. Images are then read from the disk, reshaped and augmented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzpA2WjavXFf"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2wSvwOlvXFf"
      },
      "outputs": [],
      "source": [
        "# Functions for reading images, reshaping and augmenting. Followed by wrapper functions functions\n",
        "#\n",
        "def read_image(image_file, label):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_image(image,channels=3, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "def reshape_image(image,label):\n",
        "    global target_dim\n",
        "    H = tf.shape(image)[0]      # This is very important. Dataset fails otherwise.\n",
        "    W = tf.shape(image)[1]\n",
        "    i0 = rng.uniform(shape=[1],minval=0, maxval=H-target_dim,dtype = tf.dtypes.int32)[0]\n",
        "    #i0 = np.random.randint(0,image.shape[0]-target_dim)\n",
        "    irand = rng.uniform(shape=[1])[0]\n",
        "    if irand<0.25:\n",
        "        image = image[i0:i0+target_dim,0:target_dim,:]\n",
        "    elif irand>=0.25 and irand<0.5:\n",
        "        image = image[i0:i0+target_dim,H-target_dim:H,:]\n",
        "    elif irand>=0.5 and irand<0.75:\n",
        "        image = image[0:target_dim,i0:i0+target_dim,:]\n",
        "    elif irand>=0.75:\n",
        "        image = image[W-target_dim:W,i0:i0+target_dim,:]\n",
        "    #image = tf.image.per_image_standardization(image)\n",
        "    #image = tf.linalg.normalize(image,axis=2)\n",
        "    #image = image[0]\n",
        "    #image = (image - min(image))/(max(image)-min(image))\n",
        "    return image, label\n",
        "\n",
        "def augment(image,label,seed):\n",
        "    image = tf.image.stateless_random_flip_left_right(image,seed=seed)\n",
        "    image = tf.image.stateless_random_flip_up_down(image,seed=seed)\n",
        "    image = tf.image.stateless_random_brightness(image, max_delta = 0.5, seed = seed)\n",
        "    image = tf.image.stateless_random_contrast(image,lower = 0.5,upper = 1.5,seed = seed)\n",
        "    return image,label\n",
        "\n",
        "def normalize_image(image,label):\n",
        "    imin = tf.math.reduce_min(image)\n",
        "    imax = tf.math.reduce_max(image)\n",
        "    image = (image - imin)/(imax - imin)\n",
        "    return image,label\n",
        "\n",
        "def readImagewBoundary(image_file, label,xL,yL):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_image(image,channels=3, dtype=tf.float32)\n",
        "    return image, label, xL, yL\n",
        "\n",
        "def reshapeImagewBoundary(image,label,xL,yL):\n",
        "    global target_dim\n",
        "    i0    = rng.uniform(shape=[1],minval=0, maxval=xL.shape[0],dtype = tf.dtypes.int32)[0]\n",
        "    image = image[yL[i0]:yL[i0]+target_dim,xL[i0]:xL[i0]+target_dim,:]\n",
        "    print(image.shape)\n",
        "    return image,label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtLNddnKvXFh"
      },
      "outputs": [],
      "source": [
        "# wrapper functions for training and\n",
        "#\n",
        "def wrapper_train(image_file,label):\n",
        "    image,label  = read_image(image_file,label)\n",
        "    image,label  = reshape_image(image,label)\n",
        "    seed         = rng.make_seeds(2)[0]\n",
        "    image, label = augment(image,label,seed)\n",
        "    image, label = normalize_image(image,label)\n",
        "    return image,label\n",
        "\n",
        "def wrapper_val(image_file,label):\n",
        "    image,label  = read_image(image_file,label)\n",
        "    image,label  = reshape_image(image,label)\n",
        "    image, label = normalize_image(image,label)\n",
        "    return image,label\n",
        "\n",
        "def wrapper_train_boundary(image_file,label,xL,yL):\n",
        "    image,label,xL,yL = readImagewBoundary(image_file,label,xL,yL)\n",
        "    image,label       = reshapeImagewBoundary(image,label,xL,yL)\n",
        "    seed              = rng.make_seeds(2)[0]\n",
        "    image, label      = augment(image,label,seed)\n",
        "    image, label      = normalize_image(image,label)\n",
        "    return image,label\n",
        "\n",
        "def wrapper_val_boundary(image_file,label,xL,yL):\n",
        "    image,label,xL,yL = readImagewBoundary(image_file,label,xL,yL)\n",
        "    image,label       = reshapeImagewBoundary(image,label,xL,yL)\n",
        "    image,label       = normalize_image(image,label)\n",
        "    return image,label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaorrxyIvXFh"
      },
      "source": [
        "### Make dataset and print sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGiaXP18vXFi",
        "outputId": "53742141-e9a2-4ace-fb48-ee8ec7d10d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<unknown>\n",
            "<unknown>\n"
          ]
        }
      ],
      "source": [
        "# Setup datasets\n",
        "#\n",
        "# Make training and validation dataframes\n",
        "def makeTFdatasetwBoundary(csvfile, xLfile, yLfile):\n",
        "    df         = pd.read_csv(csvfile)\n",
        "    filenames  = img_folder + df[\"filenames\"].values\n",
        "    id         = df[\"id\"].values\n",
        "    df         = pd.read_csv(xLfile,header=None)\n",
        "    xL         = np.array(df,dtype=np.int32)\n",
        "    df         = pd.read_csv(yLfile,header=None)\n",
        "    yL         = np.array(df,dtype=np.int32)\n",
        "    return tf.data.Dataset.from_tensor_slices((filenames, id, xL, yL))\n",
        "\n",
        "def makeTFdataset(csvfile):\n",
        "    df         = pd.read_csv(csvfile)\n",
        "    filenames  = img_folder + df[\"filenames\"].values\n",
        "    id         = df[\"id\"].values\n",
        "    df         = tf.data.Dataset.from_tensor_slices((filenames, id))\n",
        "    return tf.data.Dataset.from_tensor_slices((filenames, id))\n",
        "\n",
        "ds_train = makeTFdatasetwBoundary(train_csv, xL_train, yL_train)\n",
        "ds_val   = makeTFdatasetwBoundary(val_csv, xL_val, yL_val)\n",
        "ds_test  = makeTFdatasetwBoundary(test_csv, xL_test, yL_test)\n",
        "\n",
        "def configure_for_performance(ds,nBatch):\n",
        "    ds = ds.cache()\n",
        "    ds = ds.batch(nBatch)\n",
        "    ds = ds.shuffle(buffer_size=shufflenum)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "#ds_train = ds_train.map(wrapper_train_boundary, num_parallel_calls=AUTOTUNE)\n",
        "#ds_val   = ds_val.map(wrapper_val_boundary, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "ds_train = configure_for_performance(ds_train.map(wrapper_train_boundary, num_parallel_calls=AUTOTUNE),nBatchTrain)\n",
        "ds_val   = configure_for_performance(ds_val.map(wrapper_val_boundary, num_parallel_calls=AUTOTUNE),nBatchVal)\n",
        "\n",
        "#ds_train = ds_train.batch(nBatchTrain).map(read_image,num_parallel_calls=AUTOTUNE).map(wrapper_train,num_parallel_calls=AUTOTUNE).cache().shuffle(shufflenum,reshuffle_each_iteration=True).prefetch(AUTOTUNE)\n",
        "#ds_val   = ds_val.map(read_image,num_parallel_calls=AUTOTUNE).batch(nBatchVal).map(wrapper_val,num_parallel_calls=AUTOTUNE).cache().shuffle(shufflenum,reshuffle_each_iteration=True).prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "k7kaGMYqvXFk",
        "outputId": "1125108e-9a4f-48b3-d70a-2917f58684d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n",
            "(50, 50, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "images, labels = next(iter(ds_train))\n",
        "\n",
        "image = images[3].numpy()\n",
        "plt.imshow(image,cmap='gray')\n",
        "image = np.asarray(image)\n",
        "print(image.max())\n",
        "print(image.min())\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okbwp6EovXFk"
      },
      "source": [
        "\n",
        "## Model definition\n",
        "\n",
        " This section defines the model. The model maybe be custom-defined or a pre-trained model can be used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzazoFeKvXFl"
      },
      "source": [
        "### Using a pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03P-Y4iTvXFl"
      },
      "source": [
        "#### Load model and freeze layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-HU_jtkvXFl"
      },
      "source": [
        "##### MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-tga8S-vXFl",
        "outputId": "d15ce500-13da-4e8d-ee01-541a8793717f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ],
      "source": [
        "# load the pre-trained model\n",
        "#\n",
        "IMG_SHAPE = [target_dim,target_dim,3]\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpR5mAGIvXFm",
        "outputId": "d0b86e89-4dd0-42fe-9e69-75e8e0a8c26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25, 3, 3, 1280)\n"
          ]
        }
      ],
      "source": [
        "# check base model\n",
        "#\n",
        "image_batch, label_batch = next(iter(ds_train))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(target_dim,target_dim,3))\n",
        "x      = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "#base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEa2YErBvXFm"
      },
      "source": [
        "##### ResNet50V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9BjEd6JvXFn"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "#\n",
        "IMG_SHAPE = [target_dim,target_dim,3]\n",
        "base_model = tf.keras.applications.ResNet50V2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAGOHcb3vXFn",
        "outputId": "e70670a1-bd6e-4b0d-ec13-4cb098a401f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25, 3, 3, 2048)\n"
          ]
        }
      ],
      "source": [
        "# check base model\n",
        "#\n",
        "image_batch, label_batch = next(iter(ds_train))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(target_dim,target_dim,3))\n",
        "x      = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
        "#base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1vbgKo2vXFn"
      },
      "source": [
        "##### Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "4HuJXOCOvXFo",
        "outputId": "38c502cb-0b9f-4f11-c5f0-acc8b37e709d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-59d1a23474d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n\u001b[1;32m      5\u001b[0m                                               \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                               weights='imagenet')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    374\u001b[0m         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    375\u001b[0m             (input_shape[1] is not None and input_shape[1] < min_size)):\n\u001b[0;32m--> 376\u001b[0;31m           raise ValueError('Input size must be at least '\n\u001b[0m\u001b[1;32m    377\u001b[0m                            \u001b[0;34mf'{min_size}x{min_size}; Received: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                            f'input_shape={input_shape}')\n",
            "\u001b[0;31mValueError\u001b[0m: Input size must be at least 75x75; Received: input_shape=[50, 50, 3]"
          ]
        }
      ],
      "source": [
        "# load model\n",
        "#\n",
        "IMG_SHAPE = [target_dim,target_dim,3]\n",
        "base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-VQgU3wvXFo",
        "outputId": "a3e1eaf7-0b26-4944-ddd6-063b72d0ee90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25, 1, 1, 2048)\n"
          ]
        }
      ],
      "source": [
        "# check base model\n",
        "#\n",
        "image_batch, label_batch = next(iter(ds_train))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(target_dim,target_dim,3))\n",
        "#x      = tf.keras.applications.inception_v3.preprocess_input(inputs)\n",
        "#base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G21VqvTvvXFp"
      },
      "source": [
        "##### EfficientNet B7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTobEvwXvXFp"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "#\n",
        "IMG_SHAPE = [target_dim,target_dim,3]\n",
        "base_model = tf.keras.applications.EfficientNetB7(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flsDtfCkvXFp",
        "outputId": "0d5fd960-9068-44b7-bac5-8814cb66f966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25, 2, 2, 2560)\n"
          ]
        }
      ],
      "source": [
        "# check base model\n",
        "#\n",
        "image_batch, label_batch = next(iter(ds_train))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(target_dim,target_dim,3))\n",
        "#x      = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
        "#base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN470U_wvXFq"
      },
      "source": [
        "##### EfficientNet V2S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9iT0-DGvXFq"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "#\n",
        "IMG_SHAPE = [target_dim,target_dim,3]\n",
        "base_model = tf.keras.applications.EfficientNetV2S(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kucElcHJvXFq",
        "outputId": "354726d7-ade7-4eb4-c510-4ba48d68cc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 3, 3, 1280)\n"
          ]
        }
      ],
      "source": [
        "# check base model\n",
        "#\n",
        "image_batch, label_batch = next(iter(ds_train))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(target_dim,target_dim,3))\n",
        "#x      = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n",
        "#base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYYsMFjMvXFr"
      },
      "source": [
        "#### Add additional layers to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziM3GIHVvXFr",
        "outputId": "aa90da27-039d-4ac9-b998-e52087d5df11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
            "                                                                 \n",
            " efficientnetb7 (Functional)  (None, 2, 2, 2560)       64097687  \n",
            "                                                                 \n",
            " global_average_pooling2d_4   (None, 2560)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 128)               327808    \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,524,696\n",
            "Trainable params: 427,009\n",
            "Non-trainable params: 64,097,687\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Add additional layers to the model\n",
        "#\n",
        "x = base_model(inputs,training=False)       # because of the batchnorm layer\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLxi5TQ8vXFr"
      },
      "source": [
        "\n",
        "### Custom model\n",
        "\n",
        " This section defines a custom model created from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HHPgQVdvXFr",
        "outputId": "e62aa8a8-7639-4484-d8cb-9e08ba769762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 74, 74, 250)       3250      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 74, 74, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 73, 73, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 73, 73, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 73, 73, 250)       0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 72, 72, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 72, 72, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 72, 72, 250)       0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 71, 71, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 71, 71, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 71, 71, 250)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 70, 70, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 70, 70, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 70, 70, 250)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 35, 35, 250)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 34, 34, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 34, 34, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 34, 34, 250)       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 33, 33, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 33, 33, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 33, 33, 250)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 32, 32, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 32, 32, 250)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 250)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 15, 15, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 15, 15, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 15, 15, 250)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 14, 14, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 14, 14, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 14, 14, 250)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 13, 13, 250)       250250    \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 13, 13, 250)      1000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 13, 13, 250)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 250)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                288032    \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,806,927\n",
            "Trainable params: 2,801,427\n",
            "Non-trainable params: 5,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Custom model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu', input_shape=(target_dim,target_dim,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(250, (2,2),activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "\n",
        "    # Flatten\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.20),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.20),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.20),\n",
        "\n",
        "    # Output\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BhhJuPnvXFs"
      },
      "source": [
        "### Load previously-trained model\n",
        "This section will load a previously trained model to re-train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJMAsswuvXFs"
      },
      "outputs": [],
      "source": [
        "#model_path = './Models/NLBits3_C1'\n",
        "model = tf.keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-PO6OidvXFt"
      },
      "source": [
        "## Compile and train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY4IgBl7vXFt"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "#\n",
        "model.compile(loss='mean_squared_error', optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4), metrics = ['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViQAwIsGvXFt"
      },
      "outputs": [],
      "source": [
        "# add checkpoints\n",
        "#\n",
        "cp_callback  = tf.keras.callbacks.ModelCheckpoint(model_path,\n",
        "                                                  verbose = 2,\n",
        "                                                  save_best_only = True,\n",
        "                                                  save_freq = 'epoch')\n",
        "log_callback = TensorBoard(log_dir=log_path, histogram_freq=5)\n",
        "callbacks    = [cp_callback, log_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI2a-O-pvXFt",
        "outputId": "60a5bce7-ed8c-4b5a-d35d-7a49b67044f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.08046, saving model to /content/drive/MyDrive/Colab Project/Models/CrossSections_C3\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Project/Models/CrossSections_C3/assets\n",
            "69/69 - 267s - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0805 - val_mse: 0.0805 - 267s/epoch - 4s/step\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 2: val_loss improved from 0.08046 to 0.08005, saving model to /content/drive/MyDrive/Colab Project/Models/CrossSections_C3\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Project/Models/CrossSections_C3/assets\n",
            "69/69 - 242s - loss: 0.0885 - mse: 0.0885 - val_loss: 0.0801 - val_mse: 0.0801 - 242s/epoch - 4s/step\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.08005\n",
            "69/69 - 11s - loss: 0.0873 - mse: 0.0873 - val_loss: 0.0806 - val_mse: 0.0806 - 11s/epoch - 156ms/step\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0818 - val_mse: 0.0818 - 10s/epoch - 149ms/step\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0875 - mse: 0.0875 - val_loss: 0.0818 - val_mse: 0.0818 - 10s/epoch - 148ms/step\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0803 - val_mse: 0.0803 - 10s/epoch - 150ms/step\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0804 - val_mse: 0.0804 - 10s/epoch - 148ms/step\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0808 - val_mse: 0.0808 - 10s/epoch - 148ms/step\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0806 - val_mse: 0.0806 - 10s/epoch - 148ms/step\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0817 - val_mse: 0.0817 - 10s/epoch - 150ms/step\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0808 - val_mse: 0.0808 - 10s/epoch - 148ms/step\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0807 - val_mse: 0.0807 - 10s/epoch - 148ms/step\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0805 - val_mse: 0.0805 - 10s/epoch - 149ms/step\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0803 - val_mse: 0.0803 - 10s/epoch - 148ms/step\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0873 - mse: 0.0873 - val_loss: 0.0806 - val_mse: 0.0806 - 10s/epoch - 148ms/step\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0806 - val_mse: 0.0806 - 10s/epoch - 150ms/step\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 147ms/step\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0808 - val_mse: 0.0808 - 10s/epoch - 147ms/step\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0873 - mse: 0.0873 - val_loss: 0.0806 - val_mse: 0.0806 - 10s/epoch - 147ms/step\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0807 - val_mse: 0.0807 - 10s/epoch - 148ms/step\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0805 - val_mse: 0.0805 - 10s/epoch - 150ms/step\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0806 - val_mse: 0.0806 - 10s/epoch - 148ms/step\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 148ms/step\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0807 - val_mse: 0.0807 - 10s/epoch - 148ms/step\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0808 - val_mse: 0.0808 - 10s/epoch - 149ms/step\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 147ms/step\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0808 - val_mse: 0.0808 - 10s/epoch - 148ms/step\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 147ms/step\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0811 - val_mse: 0.0811 - 10s/epoch - 147ms/step\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0812 - val_mse: 0.0812 - 10s/epoch - 147ms/step\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0810 - val_mse: 0.0810 - 10s/epoch - 147ms/step\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0811 - val_mse: 0.0811 - 10s/epoch - 147ms/step\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0810 - val_mse: 0.0810 - 10s/epoch - 147ms/step\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 147ms/step\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0809 - val_mse: 0.0809 - 10s/epoch - 147ms/step\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0810 - val_mse: 0.0810 - 10s/epoch - 148ms/step\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.08005\n",
            "69/69 - 10s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0810 - val_mse: 0.0810 - 10s/epoch - 148ms/step\n",
            "Epoch 38/500\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "#\n",
        "history = model.fit(ds_train, validation_data=ds_val,verbose=2, epochs=500,callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyqCBh2-vXFt"
      },
      "source": [
        "## Testing.\n",
        "This section will load ds_test and test the model on the holdout dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvru0f35vXFu"
      },
      "source": [
        "### Evaluate and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEdZMzcuvXFu"
      },
      "outputs": [],
      "source": [
        "# Evaluate model on test data ot get loss and accuracy\n",
        "#\n",
        "neval = 10\n",
        "loss  = np.zeros(neval,1)\n",
        "acc   = np.zeros(neval,1)\n",
        "for i in range(neval):\n",
        "    loss[i], acc[i] = model.evaluate(ds_test, verbose=2)\n",
        "\n",
        "lossavg = np.mean(loss)\n",
        "accavg  = np.mean(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nA3bHIUvXFu"
      },
      "outputs": [],
      "source": [
        "# make predictions using this model\n",
        "#\n",
        "neval = 10\n",
        "y_test_pred = []\n",
        "for i in range(neval):\n",
        "    y_test_pred = [y_test_pred,model.predict(ds_test, verbose=2)]\n",
        "\n",
        "y_test_pred     = np.array(y_test_pred)\n",
        "y_test_pred_avg = np.mean(y_test_pred,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plbeUw3IvXFu"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ29eAIWvXFv"
      },
      "outputs": [],
      "source": [
        "# prepare for making plots\n",
        "#\n",
        "y_test  = list(ds_test.as_numpy_iterator())\n",
        "y_test  = np.array([i[1] for i in y_test])\n",
        "\n",
        "i0      = np.argwhere(y_test==1)\n",
        "i0      = [i[0]+1 for i in i0]\n",
        "y_test  = np.split(y_test,i0)\n",
        "y_test_pred_avg = np.split(y_test_pred_avg,i0)\n",
        "y_test  = y_test[:-1]\n",
        "y_test_pred_avg = y_test_pred_avg[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK2nt-UfvXFv",
        "outputId": "c8453aaa-7d91-4626-e99c-5227a5e3f8ad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# run loop through all data points and make plots\n",
        "#\n",
        "for i in range(len(y_test)):\n",
        "    plt.figure(i)\n",
        "    plt.plot(y_test[i],label='y_test')\n",
        "    plt.plot(y_test_pred_avg[i],label='predicted')\n",
        "    plt.legend(['Actual','Predicted'])\n",
        "    #plt.title(checkpoint_path + img_folder)\n",
        "    plt.ylim((0,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GoWbbvLvXFv"
      },
      "source": [
        "## Layer outputs\n",
        "Visualize the output of every layer of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX-93gfnvXFv",
        "outputId": "4106e74d-cff3-4716-f2be-5e6185b6c200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['conv2d_10', 'batch_normalization_10', 'conv2d_11', 'batch_normalization_11', 'conv2d_12', 'batch_normalization_12', 'conv2d_13', 'batch_normalization_13', 'max_pooling2d_2', 'conv2d_14', 'batch_normalization_14', 'conv2d_15', 'batch_normalization_15', 'conv2d_16', 'batch_normalization_16', 'dropout_4', 'max_pooling2d_3', 'conv2d_17', 'batch_normalization_17', 'conv2d_18', 'batch_normalization_18', 'conv2d_19', 'batch_normalization_19', 'dropout_5', 'flatten_1', 'dense_4', 'dense_5', 'dropout_6', 'dense_6', 'dropout_7', 'dense_7']\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Visualize the output of every layer of the model\n",
        "#\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "\n",
        "print(layer_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jRjr8CqvXFw"
      },
      "outputs": [],
      "source": [
        "lnames = [i for i in layer_names if 'conv' in i or 'pool' in i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJAPDiPKvXFw"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Build a new model with the same input as the original model\n",
        "#\n",
        "activation_model = tf.keras.models.Model(model.inputs, layer_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8ZrnbPlvXFw"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# get a sample image and feed it to the newly created model\n",
        "#\n",
        "[image,label] = wrapper_train(filenames[10], id[10])\n",
        "features = activation_model(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZeWd0pPvXFw"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Print out the results of the model\n",
        "#\n",
        "print(features.shape)\n",
        "plt.imshow(features[0,:,:,:])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "i-HU_jtkvXFl",
        "JEa2YErBvXFm",
        "t1vbgKo2vXFn",
        "gN470U_wvXFq",
        "mLxi5TQ8vXFr",
        "-BhhJuPnvXFs"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "83bdccc40ee605d34e09f49ace67acd7810c7790944946e60b6a8185dde0dd2c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
